{
  "documents": {
    "citation-376238636.ris": "Extracted partial content (PDF may be corrupted):\n\nAU  - Banh, Leonardo\nAU  - Strobel, Gero\nPY  - 2023/12/06\nT1  - Generative artificial intelligence\nDO  - 10.1007/s12525-023-00680-1\nJO  - Electronic Markets",
    "aalyze.jpeg": "(0 \u00abB\u00ae COMPILER DESIGN1.pdf - Es fs) x\nG (QOFile C/Users/sanje/AppData/Local/Packages/5319275A WhatsAppDesktop_cv1gigvanyjgm/LocalState/sessions/E67B8F7A575EB005F876FA9D3D98E7F384BD9F82/transfers/2025-43/... & = @ ~ copicr Ty\n= | we Y Daw y QO | AY | a& | Ask Copilot - + Bit of9/ Q |) a als & | 7 8 | Edit with Acrobat\na\n6\n\u00a9 |COMPILER DESIGN \u2014 IMP QUESTIONS WITH ANSWERS\nExplain the working of a Two-Pass Assembler with neat diagram and example.\nAnswer:\nAtwo-pass assembler processes the source program twice.\nPass 1:\n+ Scans source code line by line.\n+ Assigns addresses to instructions and data.\n+ Builds Symbol Table (ST), Literal Table (LT), and Pool Table (PT).\n+ Generates intermediate code.\nPass 2:\n+ Uses symbol and literal tables.\n+ Translates mnemonics into opcodes.\n+ Replaces symbols/literals with actual addresses.\n+ Produces final object code.\nDiagram:\nSource > Pass 1 > ST, LT, PT, IC > Pass 2 > Object Code > Loader\nExample: j\nSTART 200 oy\n\u2014\u2014\u2014\u2014 ENG @ oo) & 1346",
    "analysis.pdf": "SIH 2025 - Disaster Response Drone Complete Roadmap\nProblem Statement Analysis (PS ID: 25047)\nOrganization: Government of Odisha\nDepartment: Electronics & IT Department\nTheme: Robotics and Drones\nCategory: Hardware\nObjective: Develop a drone-based system to deliver medical supplies and\ncommunication devices to remote areas during natural disasters, with AI-powered real-\ntime navigation and obstacle avoidance, 5kg payload capacity, reducing response time\nby 20% in inaccessible regions.\nPhase 1: Research & Planning (Week 1-2)\n1.1 Market Research & Analysis\n\u2022 Study existing disaster response drone systems (DJI Matrice series, Zipline\nmedical drones)\n\u2022 Analyze Odisha's geographical challenges and disaster patterns\n\u2022 Research regulatory requirements (DGCA guidelines for drones in India)\n\u2022 Study similar implementations globally (Rwanda's medical drone network)\n1.2 Technical Requirements Analysis\n\u2022 Payload Requirements: 5kg capacity with secure mounting system\n\u2022 Flight Range: Minimum 50km radius for remote area coverage\n\u2022 Flight Time: 60+ minutes for effective operations\n\u2022 Weather Resistance: IP65 rating for monsoon conditions\n\u2022 Navigation: GPS + Visual SLAM for GPS-denied environments\n\u2022 Communication: 4G/5G connectivity with satellite backup\n1.3 Team Structure & Role Assignment\n\u2022 Hardware Lead: Drone assembly, payload mechanisms\n\u2022 Software Lead: Flight control, navigation algorithms\n\u2022 AI/ML Developer: Computer vision, obstacle detection\n\u2022 Mobile App Developer: Ground control station, user interface\n\u2022 System Integrator: Overall coordination, testing\nPhase 2: System Design & Architecture (Week 3-4)\n2.1 Hardware Architecture\nDrone Platform Selection:\n- Custom quadcopter/hexacopter design\n- Frame: Carbon fiber for weight reduction\n- Motors: High-efficiency brushless motors (4x or 6x)\n- Propellers: Foldable for transport efficiency\n- Battery: LiPo 6S, 22000mAh for extended flight time\n2.2 Payload System Design\n\u2022 Drop Mechanism: Servo-controlled release system\n\u2022 Parachute Deploy: Automatic deployment for fragile items\n\u2022 Compartments: Modular design for different supply types\n\u2022 Weight Distribution: Centered mounting for stability\n2.3 Sensor Integration\n\u2022 Primary Camera: 4K gimbal-stabilized for navigation\n\u2022 Depth Sensors: LiDAR for 3D mapping\n\u2022 IMU: 9-axis for flight stability\n\u2022 GPS Module: Dual-frequency for precision\n\u2022 Ultrasonic Sensors: Ground proximity detection\n\u2022 Weather Sensors: Wind speed, humidity monitoring\n2.4 Software Architecture\nGround Control System (Mobile App)\n\u251c\u2500\u2500 Mission Planning Interface\n\u251c\u2500\u2500 Real-time Monitoring Dashboard\n\u251c\u2500\u2500 Emergency Override Controls\n\u2514\u2500\u2500 Data Logging & Analytics\nFlight Control System\n\u251c\u2500\u2500 ArduPilot/PX4 based autopilot\n\u251c\u2500\u2500 Custom navigation algorithms\n\u251c\u2500\u2500 AI obstacle avoidance\n\u2514\u2500\u2500 Emergency landing protocols\nCommunication Layer\n\u251c\u2500\u2500 4G/LTE primary connection\n\u251c\u2500\u2500 LoRaWAN for long-range backup\n\u251c\u2500\u2500 Satellite communication fallback\n\u2514\u2500\u2500 Mesh networking capability\nPhase 3: Development Sprint 1 - Core Systems (Week 5-8)\n3.1 Hardware Development\nWeek 5-6: Frame & Power System\n\u2022 Assemble drone frame with motor mounts\n\u2022 Install electronic speed controllers (ESCs)\n\u2022 Integrate battery management system\n\u2022 Test basic flight capabilities\nWeek 7-8: Sensor Integration\n\u2022 Mount and calibrate IMU, GPS modules\n\u2022 Install camera and gimbal system\n\u2022 Integrate LiDAR and ultrasonic sensors\n\u2022 Complete wiring and EMI shielding\n3.2 Software Development\nWeek 5-6: Flight Control Foundation\n\u2022 Set up ArduPilot/PX4 firmware\n\u2022 Configure basic flight modes\n\u2022 Implement safety protocols\n\u2022 Test manual flight controls\nWeek 7-8: Navigation System\n\u2022 Develop waypoint navigation\n\u2022 Implement GPS failover systems\n\u2022 Create emergency return-to-home\n\u2022 Test autonomous flight modes\n3.3 Mobile App Development\nWeek 5-8: Ground Control Station\n\u2022 Design user interface mockups\n\u2022 Implement mission planning features\n\u2022 Create real-time telemetry display\n\u2022 Develop communication protocols\nPhase 4: Development Sprint 2 - AI & Advanced Features (Week 9-12)\n4.1 Computer Vision & AI Development\nWeek 9-10: Object Detection\n\u2022 Train models for obstacle detection (trees, buildings, power lines)\n\u2022 Implement real-time image processing\n\u2022 Develop landing zone identification\n\u2022 Create weather condition assessment\nWeek 11-12: Navigation AI\n\u2022 Implement SLAM for GPS-denied navigation\n\u2022 Develop dynamic path planning algorithms\n\u2022 Create collision avoidance system\n\u2022 Test AI decision-making in simulated environments\n4.2 Payload Delivery System\nWeek 9-10: Mechanical Systems\n\u2022 Design and 3D print payload containers\n\u2022 Implement servo-controlled drop mechanism\n\u2022 Develop parachute deployment system\n\u2022 Test payload release accuracy\nWeek 11-12: Smart Delivery\n\u2022 Implement GPS-coordinate based dropping\n\u2022 Develop visual confirmation system\n\u2022 Create delivery status reporting\n\u2022 Test with various payload types\n4.3 Communication Systems\nWeek 9-12: Multi-layered Communication\n\u2022 Implement 4G/LTE connectivity\n\u2022 Develop LoRaWAN backup system\n\u2022 Create mesh networking capability\n\u2022 Test communication range and reliability\nPhase 5: Integration & Testing (Week 13-16)\n5.1 System Integration\nWeek 13-14: Hardware-Software Integration\n\u2022 Integrate all sensors with flight controller\n\u2022 Calibrate AI algorithms with real hardware\n\u2022 Test end-to-end communication systems\n\u2022 Resolve integration issues\n5.2 Field Testing\nWeek 15: Controlled Environment Testing\n\u2022 Test in simulated disaster scenarios\n\u2022 Validate payload delivery accuracy\n\u2022 Test obstacle avoidance in controlled space\n\u2022 Measure flight performance metrics\nWeek 16: Real-world Validation\n\u2022 Conduct tests in actual remote locations\n\u2022 Test various weather conditions\n\u2022 Validate 20% response time improvement\n\u2022 Gather performance data\n5.3 Safety & Compliance Testing\n\u2022 DGCA compliance verification\n\u2022 Fail-safe mechanism testing\n\u2022 Emergency protocols validation\n\u2022 Risk assessment documentation\nPhase 6: Optimization & Final Preparation (Week 17-20)\n6.1 Performance Optimization\nWeek 17-18: System Tuning\n\u2022 Optimize flight algorithms for efficiency\n\u2022 Improve AI model accuracy\n\u2022 Enhance battery life and flight time\n\u2022 Streamline user interface\n6.2 Documentation & Presentation Prep\nWeek 19-20: SIH Preparation\n\u2022 Create technical documentation\n\u2022 Develop presentation materials\n\u2022 Prepare demonstration scenarios\n\u2022 Create video documentation\n6.3 Final Testing & Validation\n\u2022 Complete system stress testing\n\u2022 Validate all performance metrics\n\u2022 Prepare backup systems\n\u2022 Final safety checks\nTechnical Implementation Details\nHardware Stack\nFlight Controller: Pixhawk 4 / Cube Orange\nCompanion Computer: Raspberry Pi 4 / Jetson Nano\nCommunication: 4G module + LoRa + WiFi\nSensors: GPS RTK, IMU, Magnetometer, Barometer\nVision: RealSense D455 depth camera\nMotors: T-Motor U8 Pro (6x for hexacopter)\nBattery: 6S 22000mAh LiPo\nSoftware Stack\nFlight Software: ArduPilot / PX4\nCompanion Software: Python/ROS2\nComputer Vision: OpenCV, TensorFlow/PyTorch\nMobile App: Flutter/React Native\nBackend: Node.js/Django with PostgreSQL\nCloud Services: AWS/Google Cloud for ML training\nAI/ML Components\n\u2022 Object Detection: YOLOv8 for real-time obstacle detection\n\u2022 Path Planning: A* algorithm with dynamic updates\n\u2022 Image Recognition: CNN for landing zone identification\n\u2022 Predictive Modeling: Weather pattern analysis for route optimization\nKey Performance Indicators (KPIs)\nPrimary Metrics\n\u2022 Response Time Reduction: Target 20% improvement over traditional methods\n\u2022 Payload Accuracy: 95% successful deliveries within 10m radius\n\u2022 Flight Reliability: 99% successful mission completion rate\n\u2022 Battery Efficiency: 60+ minute flight time with 5kg payload\nSecondary Metrics\n\u2022 Weather Adaptability: Operations in 25+ km/h winds\n\u2022 Communication Range: 50+ km reliable connectivity\n\u2022 AI Accuracy: 95+ % obstacle detection accuracy\n\u2022 User Experience: <5 minute mission setup time\nRisk Management & Mitigation\nTechnical Risks\n\u2022 Battery Life: Implement swappable battery system\n\u2022 Communication Loss: Multi-layer backup communication\n\u2022 Weather Conditions: Advanced weather monitoring and planning\n\u2022 Regulatory Issues: Early DGCA consultation and compliance\nProject Risks\n\u2022 Timeline Delays: Modular development approach\n\u2022 Component Availability: Maintain backup supplier list\n\u2022 Team Coordination: Regular daily standups and weekly reviews\n\u2022 Budget Constraints: Prioritize core features first\nBudget Estimation\nHardware Costs (\u20b980,000 - \u20b91,20,000)\n\u2022 Drone frame and motors: \u20b925,000\n\u2022 Flight controller and sensors: \u20b920,000\n\u2022 Camera and gimbal: \u20b915,000\n\u2022 Communication modules: \u20b910,000\n\u2022 Batteries and chargers: \u20b915,000\n\u2022 Miscellaneous components: \u20b910,000\nSoftware & Development\n\u2022 Cloud services: \u20b95,000\n\u2022 Development tools: \u20b93,000\n\u2022 Testing and validation: \u20b95,000\nInnovation Highlights\nUnique Features\n1. Multi-Modal Communication: 4G + LoRaWAN + Satellite backup\n2. Weather-Adaptive AI: Dynamic route planning based on real-time weather\n3. Modular Payload System: Quick-change containers for different supplies\n4. Mesh Network Capability: Drones can relay communications\n5. Visual Confirmation: AI-powered delivery confirmation\n6. Emergency Override: Ground control emergency intervention\nTechnology Differentiators\n\u2022 Advanced computer vision for GPS-denied navigation\n\u2022 Machine learning for predictive maintenance\n\u2022 Real-time weather integration for safe operations\n\u2022 Automated mission planning with minimal user input\nPost-SIH Development Roadmap\nShort-term (6 months)\n\u2022 Production-ready prototype refinement\n\u2022 Pilot deployment with Odisha government\n\u2022 User feedback integration\n\u2022 Regulatory approvals\nMedium-term (1-2 years)\n\u2022 Scale to other states and disaster-prone regions\n\u2022 Integration with existing emergency response systems\n\u2022 Advanced AI features and autonomous swarm coordination\n\u2022 Commercial partnerships for sustainable deployment\nLong-term (3-5 years)\n\u2022 National disaster response network\n\u2022 International expansion\n\u2022 Advanced medical capabilities (blood transport, defibrillators)\n\u2022 Integration with IoT sensors for predictive disaster response\nSuccess Criteria for SIH\nTechnical Demonstration\n\u2022 Live demonstration of autonomous flight\n\u2022 Real payload delivery with accuracy measurement\n\u2022 AI obstacle avoidance in action\n\u2022 Multi-communication system demonstration\n\u2022 Mobile app functionality showcase\nPresentation Requirements\n\u2022 Clear problem-solution fit\n\u2022 Technical innovation explanation\n\u2022 Scalability and impact demonstration\n\u2022 Business model and sustainability\n\u2022 Team expertise and execution capability\nThis roadmap provides a comprehensive path to developing a winning solution for SIH\n2025 while addressing the real-world needs of disaster response in challenging terrains\nlike Odisha.",
    "genai.pdf": "Technology in Society 81 (2025) 102813\nContents lists available at ScienceDirect\nTechnology in Society\njournal homepage: www.elsevier.com/locate/techsoc\nGenerative Artificial Intelligence (GenAI) in the research process \u2013 A survey\nof researchers\u2019 practices and perceptions\nJens Peter Andersena,* , Lise Degna , Rachel Fishberga , Ebbe K. Graversena ,\nSerge P.J.M. Horbachb , Evanthia Kalpazidou Schmidta , Jesper W. Schneidera ,\nMads P. S\u00f8rensena\naDanish Centre for Studies in Research and Research Policy, Department of Political Sciences, Aarhus University, Bartholins All\u00b4e 7, 8000, Aarhus C, Denmark\nbInstitute for Science in Society, Faculty of Science, Radboud University, Heyendaalseweg 135, 6525 AJ, Nijmegen, Netherlands\nA R T I C L E I N F O A B S T R A C T\nKeywords: This study explores the use of generative AI (GenAI) and research integrity assessments of use cases by re-\nGenerative Artificial Intelligence (GenAI) searchers, including PhD students, at Danish universities. Conducted through a survey sent to all Danish re-\nResearch process searchers from January to February 2024, the study received 2534 responses and evaluated 32 GenAI use cases\nResearch practice\nacross five research phases: idea generation, research design, data collection, data analysis, and writing/\nuse cases\nreporting. Respondents reported on their own and colleagues\u2019 GenAI usage. They also assessed whether the\nResearch integrity\npractices in the use cases were considered good research practice. Through an explorative factor analysis, we\nidentified three clusters of perception: \"GenAI as a work horse\", \"GenAI as a language assistant only\", and \"GenAI\nas a research accelerator\". The findings further show varied opinions on GenAI\u2019s research integrity implications.\nLanguage editing and data analysis were generally viewed positively, whereas experiment design and peer re-\nview tasks faced more criticism. Controversial areas included image creation/modification and synthetic data,\nwith comments highlighting the need for critical and reflexive use of GenAI. Usage differed by main research\narea, with technical and quantitative sciences reporting slightly higher usage and more positive assessments.\nJunior researchers used GenAI more than senior colleagues, while no significant gender differences were\nobserved. The study underscores the need for adaptable, discipline-specific guidelines for GenAI use in research,\ndeveloped collaboratively with experts to align with diverse research practices and minimize ethical and prac-\ntical misalignment.\n1. Introduction enthusiastic adoption [4,5] to cautious valuation [6,7] and scepticism\n[8\u201310]. Following an avalanche of opinion pieces and conceptual con-\nResearch employing Generative Artificial Intelligence (GenAI) is tributions, empirical studies offering valuable insights into GenAI\u2019s\nrapidly expanding across fields and is anticipated to accelerate and adoption, perceptions, and anticipated impacts across different schol-\ntransform scientific knowledge [1]. As in many other parts of society, arly activities are currently emerging. Studies acknowledge GenAI\u2019s\nthe integration of GenAI into academic research is characterised by a potential for efficiency gains and enhanced research processes, on one\nwide range of attitudes, perceptions, and yet to be developed practices. hand, while also revealing researchers\u2019 concerns about transparency,\nOwing to the inherent uncertainties that come along with new tech- misinformation, biases, and generally unknown implications on the\nnologies, fierce debates have emerged over the potential benefits, risks other [11].\nand challenges of using GenAI for research purposes (e.g. Ref. [2,3]). As While existing research has provided a foundation for understanding\nthe technology continues to reshape academic landscapes, understand- the complexities of GenAI adoption, limited empirical work has sys-\ning the adoption and impacts of GenAI in research practices becomes tematically explored its diverse use and perceptions across academic\nincreasingly important. The currently evolving discourse surrounding contexts and research fields. This includes variations between disci-\nGenAI within academia reflects a spectrum of engagement ranging from plines or ways of conducting research, as well as potential disparities\n* Corresponding author. Danish Centre for Studies in Research and Research Policy Aarhus University Bartholins All\u00b4e 7, 8000 Aarhus C, Denmark.\nE-mail address: jpa@ps.au.dk(J.P. Andersen).\nhttps://doi.org/10.1016/j.techsoc.2025.102813\nReceived 10 September 2024; Received in revised form 12 November 2024; Accepted 7 January 2025\nAvailable online 9 January 2025\n0160-791X/\u00a9 2025 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).\nJ.P. Andersen et al. T e c h n o l o g y in S o c i e t y 81 (2025) 102813\nacross career stages, gender and other demographics. Furthermore, and enhancing human-AI collaborations, albeit with concerns about\nquestion remain about not only whether, but how academics might use potential ethical and transparency issues.\nGenAI in research and how they assess its research integrity implications Apart from this host of survey studies on researchers\u2019 use and per-\nacross various use cases. Indeed, research practices as diverse as plan- ceptions of GenAI, two other empirical studies are worth mentioning\nning experiments, writing project proposals, generating and collecting here. A systematic review of the literature on guidelines and standards\ndata, analysing it, reporting it or transforming it into lay-accessible on how to use GenAI and Large Language Models (LLMs) in academic\ncontent can all potentially be assisted or conducted by GenAI tools. medicine [21] came to five recommendations for which they feel there is\nHowever, whether researchers actually do this and how they assess sufficient consensus among the research community, including state-\nresearch integrity aspects of using GenAI for these various cases, remains ments like Chatbots not being allowed as an author in scientific manu-\nlargely unknown. scripts; humans must be held accountable for use of ChatGPT/LLM and\nWhile several actors are preparing policy interventions to steer the contents created by ChatGPT/LLM should be meticulously verified by\nusage of GenAI in research (e.g., publishers, funders or research in- humans. The study highlights the necessity for robust guidelines to\nstitutions aiming to govern particular research practices, e.g. Committee govern GenAI\u2019s academic use, advocating for accountability in\non Publication Ethics [12]), systematic understandings of researchers\u2019 AI-generated content. This need for clarity and oversight is crucial as\nown practices become increasingly important. Indeed, such policy ini- evidenced by Gray\u2019s [22] quantitative analysis, which discovered a\ntiatives tend to remain paper tigers if not properly aligned with practices noticeable uptick in LLM-assisted publications within engineering and\nof those they tend to govern [13]. This paper aims to deepen our un- natural sciences \u2013 a trend that highlights the differential adoption rates\nderstanding of GenAI\u2019s role in academia based on the results of a across disciplines. Gray estimates that up to 85,000 LLM-assisted articles\nnationwide survey of researchers across Danish universities. By were published in 2023, indicating significant adoption of GenAI in\nexploring how researchers from diverse backgrounds, fields and schol- academic publishing, for which other papers have provided (more\narly traditions use and assess the application of GenAI for a wide range anecdotal) evidence too. We note that the literature of studies examining\nof research tasks, this paper seeks to contribute to a more comprehensive GenAI use in the research process is likewise quickly developing and any\nunderstanding of GenAI\u2019s evolving role within academia. Ultimately, overview will inevitably only provide a snapshot of the current state of\nthis is intended to inform the preparation of tailored guidelines and affairs.\nmodels of accountability. Apart from empirical work on the adoption, perceptions and impli-\ncations of GenAI in research contexts, the ethical implications of this\n1.1. Overview of other relevant studies new technology have been hotly debated. Multiple ethical principles in\nquestion have been highlighted and based on a literature review, Ning\nIn examining the current landscape of GenAI within academia, et al. [23] identified nine key principles to be used to build an ethical\nseveral studies have offered insights into its adoption, perceptions, and framework for GenAI use in health care: accountability, autonomy, eq-\nanticipated impacts across various scholarly activities. While most uity, integrity, non-maleficence, privacy, security, transparency, and\nstudies have focused on the use of GenAI in educational and teaching trust. These nine ethical dimensions are all related to broader ethical\ncontexts, several have also examined research contexts. Notably, a sur- principles such as honesty (related to integrity) and fairness (related to\nvey at a large U.S. research university revealed mixed attitudes among equity). Ning et al. [23] use them to form a check list called \u201cTrans-\nfaculty and students towards GenAI, with a general openness to training parent Reporting of Ethics for Generative AI (TREGAI)\u201d that can be used\ndespite low current usage and comfort levels, particularly in research to strengthen ethical considerations on the use of GenAI within health\ncontexts [14]. Contrastingly, a survey among higher education faculty care and beyond. While these principles relate to the use of GenAI in\nreported a modest but growing integration of GenAI in research activ- multiple contexts, its use for research purposes raises additional ques-\nities, marking a 13-percentage point increase between spring and fall tions, for example related to authorship issues [24], copyright and in-\n2023 (9 % vs. 22 %) [15]. tellectual property [25], and reproducibility and open science [24].\nA survey among users of ResearchGate and Academia.edufound that While many have called for swift actions in terms of improved ethical\nreasons for researchers to use GenAI in their work are mainly related to guidance and regulations (e.g. Ref. [26]), others acknowledge the\ntimesaving, self-efficacy, self-esteem and reduction of stress. Conversely, fast-moving nature of this technology and the implication that any\nconcerns over academic integrity and negative peer evaluations of regulation is doomed to become outdated or obsolete soon after its\nGenAI usage, limit researchers\u2019 inclination to use GenAI tools for their development. Based on a Delphi process involving a panel of scholars\nwork [16]. from the social sciences, law, ethics, and scientific publishing, re-\nAdditionally, several surveys were conducted in the context of the searchers co-created a set of core principles informing the responsible\nNature portfolio of journals. A survey among authors of Nature articles use of GenAI in research. This approach aims to allow flexible use under\nand readers of Nature Briefing [11] found that while a large minority of conditions of diverse technological developments and stipulates re-\nresearchers engaged with AI frequently, many expressed concerns about searchers to adhere to (principles of) regulation, data security, quality\nmisinformation and biases, yet recognized benefits such as efficiency control, originality, bias mitigation, accountability, transparency and\ngains and improved accessibility for non-native English speakers. wider impact [27]. The latter notably also included social and climate\nAnother survey conducted by Nature among 3838 postdocs indicated justice.\nsimilar level of engagement with GenAI, particularly chatbots, with 31\n% of respondents reporting using chatbots. Interestingly, a majority (67 1.2. Research objective and questions\n%) felt AI had not significantly altered their day-to-day work or career\nplans [17]. Similarly, a survey among readers of the Nature journal The empirical studies mentioned above collectively indicate an\nsuggested a diversely engaging but cautious approach towards GenAI in evolving uptake of GenAI technologies in the academic community. The\nacademia [18]. Out of the 40 % that used GenAI at least occasionally, insights reflect a spectrum of engagement, from enthusiastic adoption to\nmost report using it for coding tasks or to help write manuscripts, pre- fierce scepticism, which is still in flux. This evolution is evident in the\npare presentations or conduct literature reviews. significantly different results observed in subsequent waves of similar\nFurthering this discourse, findings from a UK-based survey high- surveys. However, up to this point, studies have suggested some varia-\nlighted that over half of the academics utilized GenAI for efficiency, tions but have failed to systematically examine the diversity of GenAI\nexpecting its role to expand significantly [19]. This sentiment mirrors use and perceptions across academic contexts. This includes variations\nthe European Research Council\u2019s [20] survey results, which anticipated between disciplines or ways of doing research, as well as potential\nAI (not necessarily generative AI) fostering faster academic processes variations across career stages and other demographics. In addition,\n2\nJ.P. Andersen et al. T e c h n o l o g y in S o c i e t y 81 (2025) 102813\nrelatively little is known about how academics use GenAI in their work 2.2. Survey instrument and respondents\nand how they assess the research integrity of different GenAI practices, if\nthey think of them as good or bad research practices. The full survey instrument can be found on the project\u2019s OSF page\nIn this study, we aim to address these knowledge gaps by conducting [37]. The survey consisted of two phases. In the first phase, we collected\na nation-wide survey of researchers at Danish universities. We examine demographic and other background variables on the participants,\nhow researchers from various backgrounds and scholarly traditions use including gender, academic age, native language, academic field and\nand assess the use of GenAI for a wide range of research tasks. In the knowledge production ways (e.g. quantitative or qualitative social sci-\nremainder of this article, we will report the results of this survey and ences, theoretical or experimental natural science, etc.), participants\u2019\nreflect on the implications for regulating GenAI use for research pur- exposure to institutional regulations and conversations about AI, and the\nposes. Our article will be guided by two research questions. extent to which they use GenAI either professionally or personally. In\nthe second phase, participants were presented with 32 potential use\n1. For what purposes and to what extent is GenAI applied for research cases of AI, divided into five research phases (see Table 1). For each use\nat Danish universities by researchers across different disciplines/ case, they were asked to consider if they had recently used AI for this\nresearch fields, career stages and demographics? purpose, if they were aware of colleagues with whom they had collab-\n2. What are the overall research integrity assessments of researchers orated over the last year who had done so, and whether they considered\ntowards the integration of GenAI in academic research? How do the use case to be a good or problematic research practice. The survey\nattitudes towards GenAI vary across different scientific fields, career concluded with two open questions asking respondents whether they\nstages, and demographics (e.g., gender, seniority)? had one or multiple specific GenAI tools in mind when completing the\nsurvey and providing them the opportunity to leave any additional\n2. Methods comments they wanted to share.\nOut of the 29,498 invitations, we received 2534 complete responses\nA description of the survey, the sampling process and analysis plan (8.6 %), with another 533 respondents answering part of the questions\nwere described prior to launching the survey and uploaded to OSF [37]. (1.8 %). Table 1 \u2013 table supplements 1\u20134 present an overview of the\nsurvey respondents and their self-reported demographic and disci-\n2.1. Study participants plinary backgrounds. It also compares respondents\u2019 characteristics with\nThe survey was fielded as a census of all researchers at Danish uni-\nTable 1\nversities. Previous studies have indicated that research practices and\nways of producing knowledge, as well as researchers\u2019 assessment of Overview of use cases per research phase. ID column shows the codes used in the\nanalyses, corresponding to the use cases.\ngood and bad research practices, strongly differ between researchers\nfrom different research backgrounds, demographics and institutional Phase Use case ID\ncontexts [28]. Therefore, we aimed to reach researchers from all main Idea Generation help identify gaps in current research idea1\nareas of research. As the accessibility and legal framework impacting the help identify relevant literature idea2\nhelp summarize or analyse existing literature idea3\nuse of novel technologies and generative AI in particular, differs across\nhelp identify potential collaborators idea4\nnational contexts [29], we decided to field our survey in a single\nhelp propose new hypotheses idea5\ncountry, in order to minimize variation in this respect. Together, these Research Design suggest a structure for research proposals rd1\nconsiderations resulted in our choice of including all researchers help draft parts of a research proposal rd2\nincluding PhD students at Danish universities as our participants. Par- refine or edit language of research proposals rd3\nrefine or edit content of research proposals rd4\nticipants were sampled by collecting contact details from the institu-\nhelp design research methodology rd5\ntional personal webpages of the researchers. A script was written to help develop theoretical models or conceptual rd6\nautomatically collect the email addresses of all research staff of Danish frameworks\nuniversities. This resulted in 50,652 people with contact details and job help design experiments rd7\nData Collection suggest experimental parameters dc1\ntitles. As we were only interested in staff members with research tasks,\nhelp formulate questions for surveys or interviews dc2\nwe selected all job titles that occurred at least 50 times (118 job titles)\ngenerate synthetic data sets dc3\nand suggested an academic position that might involve research tasks transcribe recordings of research material (e.g. dc4\n(leaving 88 different job titles). This resulted in 30,590 people. interviews, workshops or focus groups).\nRemoving duplicates (e.g. researchers working at multiple departments, identify ethical issues in research (either your own or dc5\nsomeone else\u2019s)\nhence having multiple email addresses) and inactive email addresses,\nData Analysis create or edit software code for data analysis da1\nthe survey was sent out to 29,498 researchers including PhD students at create or edit simulation software code da2\nDanish universities on Jan 22nd, 2024. Two reminders were sent to support statistical data analysis da3\nresearchers who had not fully completed the survey and had not opted help pattern recognition in data da4\nout of receiving further communication about it. These waves of in- create or modify scientific figures or images da5\nWriting and suggest a structure for a research article pub1\nvitations were sent to 27,978 and 26,670 researchers respectively.\nReporting help draft parts of a research article pub2\nBefore starting the survey, participants were asked to confirm that they propose a title, abstract or keywords for your article pub3\nare: \u201can active researcher at a Danish university holding a PhD degree edit a research article to improve readability and/or pub4\n(or equivalent)\u201d or are \u201ca PhD student\u201d. language\nformat references pub5\nPrior to sending out the full survey, 200 researchers were randomly\nidentify strengths and weaknesses in a manuscript pub6\nselected from our sample to conduct a pilot survey. They received the during the peer review process\nfull survey, with the additional request to flag any mistakes or phrases help write review reports during the peer review pub7\nthat were unclear. This led to minor adjustments of the survey process\ninstrument. translate one of your research papers into a different pub8\nlanguage\nAfter concluding the survey, identifying information that had been\nhelp create (parts of) a slide deck for a conference talk pub9\nused to contact respondents was removed, without links to other data or similar academic event\nsources. All analyses were done on this data set. The qualitative re- help create lay summaries or similar non-academic pub10\nsponses were further reviewed to remove potentially identifying infor- writing for public engagement, based on your own\ntexts\nmation from the published data set.\n3\nJ.P. Andersen et al. T e c h n o l o g y in S o c i e t y 81 (2025) 102813\nthe full study population in terms of gender and disciplinary back- \u2019Assessment of good or bad practice\u2019, \u2019Description of GenAI as a tool\u2019,\nground. Gender of the non-respondents was inferred using first names \u2019Thoughts or issues related to policy, training, or infrastructure for\nand disciplinary background was inferred from non-respondents\u2019 GenAI\u2019, \u2019Examples of use\u2019, and \u2019General opinions or emotions about\ndepartmental affiliation. GenAI\u2019. The comments and coding results can be found on the project\u2019s\nOSF site [37]. Here, we have removed any identifying information from\n2.3. Description of quantitative analyses the open text fields, including names, university details, department or\nspecific research fields, and any particular activities mentioned by re-\nAll quantitative analyses were performed using R version 4.3.2. spondents that could lead to identification. To help us analyse the three\nMultiple imputation was done using the \u2018mice\u2019 package [30]. clusters identified in this paper, we specifically focused on the 182\nThe categorical academic age variable was constructed from a binary comments coded under \u2019Assessment of good or bad practice\u2019.\nresponse on whether the respondent was a current PhD student, and a\nyear for when the PhD-degree was awarded. We recoded these years to 3. Results\nroughly correspond to the categories of European Research Council\ngrant levels, so that respondents with a PhD from after 2016 are The purpose of this initial study has been to document the use of\n\u201cstarting\u201d, those with a PhD before 2017 and after 2010 are \u201cconsoli- GenAI and research integrity assessments among researchers. It is\ndators\u201d and those with a PhD from before 2011 are \u201cadvanced\u201d. therefore primarily descriptive, focused on gathering data and reporting\nFor the purpose of calculating aggregated scores and imputing and discussing evidence. The collection of literature informing the study\nmissing values, we also created recoded versions of all numerical values provided an overview of the most present empirical research evidence in\nof responses to personal use and the use of others, so that the responses this fast-developing topic area. The potential key characteristics and\n\u201cNo\u201d and \u201cNot relevant for me\u201d were recoded to 0, \u201cYes\u201d to 1, and \u201cDon\u2019t factors for the use of GenAI and research integrity assessments among\nknow\u201d to missing value. Research integrity assessments were recoded for researchers were identified, operationalized, included, and measured in\nreadability purposes only, as the value 1 corresponded to \u201cexcellent\u201d the study\u2019s data collection as reported in section two and this section.\nand 7 to \u201cvery problematic\u201d. We reversed this scale and converted the The study does not delve into potential causal factors behind differing\nvalue 8 (\u201cUnable to answer\u201d) to missing values. perceptions of GenAI use, as this would require additional, nonstruc-\nThe multiple imputation was done in two batches, one for the two tured data, i.e. interviews which have not yet been collected.\nusage groups of variables, and one for the research integrity assessment\nvariables. As the usage variables are binary, we used logistic regression, 3.1. Descriptive overview of main results\nwhile we used predictive mean matching for the assessments. Both\nbatches ran through 20 iterations. The survey was launched on January 22, 2024, and remained open\nThe imputed data are used for both the reported aggregate scores and until February 26, 2024, with one invitation and two reminders being\nthe factor analysis. Aggregated use scores are the mean use of an indi- sent to all researchers (incl. PhD students) of all eight Danish univer-\nvidual respondents, and corresponds to the proportion of use cases, the sities. Out of the 29,498 invitations, we received 2534 complete re-\nrespondent has said \u201cyes\u201d to using GenAI for. The aggregated research sponses (8.6 %), with another 533 respondents answering part of the\nintegrity assessment is the mean value of these assessments, ranging questions (1.8 %). In the analyses below, we only use the complete re-\nfrom 1 (all use cases are rated very problematic) to 7 (all use cases are sponses. The survey consisted of two main parts, one with questions\nrated excellent). regarding general GenAI experience and demographic background\nFactor analysis was done using the \u2018psych\u2019 package in R [31]. We variables, the other presenting 32 use cases across five phases of\nused parallel analysis to identify three factors with an eigenvalue above research work (Table 1). For each use case, respondents were asked\n1. We use a maximum likelihood factoring method with varimax rota- about their own use, the perceived use of others, and an assessment of\ntion, to select factors with distinct peak loadings. The resulting loadings the use case in terms of research integrity on a 7-point Likert scale from\nare high, with several peaks above .6, and 49.1 % of the variance excellent research practice to very problematic research practice.\nexplained. While the explained variance is not exceptional, we still Further details about the survey can be found in the methods section.\nconsider it reasonable. Adding two additional factors would only explain Respondents were generally well spread across disciplinary back-\n5.7 % more of the variance, which would not be justifiable, and intro- grounds and demographics. We refer to Supplementary Table 1-Sup-\nduce noisy factors. plementary Table 4 for a descriptive overview of respondents\u2019\nUsing the individual factor scores per observation, we cluster ob- background and demographics relative to the study population.\nservations with k-means clustering with three centres, equivalent to the In this section, we present descriptive statistics on the use and\nnumber of factors. Hierarchical clustering visually supports the number research integrity assessment of the 32 cases of GenAI use in the research\nof clusters. These clusters group respondents while the factor loadings process. Fig. 1presents a plot of the research integrity assessment and\ngroup the variables. average use (both own use and the perceived use of colleagues) of each\nof the individual use cases. It shows a rather wide distribution of\n2.4. Description of qualitative analyses research integrity assessments for most use cases, indicating diverse\nopinions about whether using GenAI tools for these purposes constitutes\nThe qualitative data we utilized was gathered from two open-text problematic or good research practices. In general, respondents assessed\nfield questions included in the survey. The first question asked re- using GenAI for language editing use cases (e.g. in proposal writing,\nspondents about the types of GenAI tools they used, and the second, editing of research articles, formatting references) and those related to\nbroader question sought their comments or insights related to using data analysis (e.g. creating codes for analysis or simulation, pattern\nGenAI for research purposes. recognition, transcription of research recordings) as rather good\nThe responses to the first question were compiled and visualized in research practices. In contrast, usage of GenAI for arguably more\nbar graphs, segmented by gender, PhD age, research field, and whether fundamental tasks related to designing research experiments or theo-\nthe researchers were mono-disciplinary or multidisciplinary (Fig. 2 - retical frameworks and critical assessment of other work during peer\nfigure supplements 1\u20135). review was considered more problematic.\nAs for the second question, we received a total of 543 comments Two use cases that were particularly contentious were those related\n(excluding responses that indicated \u2018no comment\u2019). To analyse the to the creation or modification of images and figures, and the creation of\ncomments, we categorized the responses into emerging thematic groups: synthetic data. Both these cases might have different connotations in\n\u2019No comment\u2019, \u2019Understanding of the survey or elaboration of answers\u2019, diverse research fields. An important observation in relation to the\n4\nJ.P. Andersen et al. T e c h n o l o g y in S o c i e t y 81 (2025) 102813\nFig. 1. Research integrity assessment scores and share of participants using GenAI for specific use cases. Results are shown by research phase. Brown bars\nshow the shares of respondents judging the use case as a problematic practice, while green bars show positive assessments. Light gray bars are the share of neutral\nresponses. Blue dots in the right panel show how large a share of respondents that report ever having used AI for the specific use case, while yellow dots show the\nshare of respondents who report that they believe their colleagues use AI for this use case. Horizontal lines in the right panel serve as visual guides only.\nresearch integrity assessment is that many respondents elaborate in the This is further underlined by aggregated assessment and usage scores\nopen text field of the survey [37], that their integrity assessment of the (see Supplementary Fig. 1), illustrating higher assessment scores, and\nuse of GenAI depends on it being used critically and reflexively. As one lower variance, as usage grows. Respondents that had not used GenAI, or\nrespondent puts it: only had used it in very few use cases, had much higher disagreement on\nthe assessment of the use cases on average.\n\u201cAlthough I have answered in many cases that using AI is excellent\nFig. 2presents the aggregated use and research integrity assessment\npractice, this does not mean that it should be used uncritically or without\nof all 32 use cases, broken down by research field (top panel), knowl-\nchecking references etc. I just consider AI as giving an excellent head start\nedge production ways (second panel), gender (third panel) and aca-\non all of these tasks\u201d (ID19826).\ndemic age (bottom panel). It shows relative consistency in responses\nThe qualitative comments, allowing respondents to contextualise across main research areas, with most users in all disciplines indicating\ntheir responses, contain several descriptions indicating a lack of trust in to use GenAI tools for only few use cases. However, a somewhat larger\nGenAI. The main problems mentioned are hallucination (that the chat- proportion of respondents from the technical sciences, especially those\nbot \u201cmakes up\u201d information), violation of privacy rights and copyrights in the experimental technical sciences, indicate to use GenAI for a higher\n(not knowing what is allowed to be fed into e.g. GenAI tools), potential number of different use cases, some even for more than half of all use\nbiases, and \u2019black boxing\u2019 of the generative process. cases mentioned in our survey. Simultaneously, respondents from the\nGenerally, we observe a moderate positive correlation between the technical sciences have the highest aggregated research integrity\nresearch integrity assessment of use cases and their admitted use by assessment of our 32 use cases. In contrast, scholars from the humanities\nrespondents (Kendall\u2019s \u03c4 =.44) or their colleagues (\u03c4 =.5). Some ex- indicate to use GenAI tools least frequently and they also have the least\nceptions are the use of GenAI to identify potential collaborators and to positive research integrity assessment of the use of GenAI for research\ncreate synthetic datasets (relatively low use), and to propose a title, purposes. Some of the respondents from this main area of research\nkeyword or abstract or even help draft parts of the body of an article indicate to have a strongly negative research integrity assessment of the\n(with relatively high admitted use). For all use cases, the reported use of usage of such tools for many use cases. A substantial share of re-\nGenAI of direct colleagues is higher than that of respondents themselves, spondents from the humanities (19.3 %) gives an overall assessment of 3\nwith particularly large relative differences for the two use cases related or less on a 7-point scale (i.e. degrees of \u2018problematic research practice\u2019).\nto the peer review process (identifying strengths and weaknesses of Looking at differences within research fields, we note that quanti-\nmanuscripts under review and writing review reports). This is in line tative social scientists indicate to use GenAI tools for substantially more\nwith what is found in other surveys, e.g. focusing on questionable use cases than their colleagues from the qualitative social sciences.\nresearch practices and malpractice [32]. Again, we notice the inverse pattern in terms of research integrity\nLast, we note that for almost all use cases, the share of respondents assessment, i.e. the qualitative social scientists giving slightly lower\nindicating a use case to be a good, very good or excellent practice is scores to the acceptability of using GenAI tools for various purposes.\nhigher than the share of respondents indicating to have used GenAI for In terms of gender, no differences in either use nor ethical assessment\nthis purpose. This suggests that, while reported use of GenAI is still fairly were observed between men and women. Some variations are reported\nlow, the reason for not engaging in more use cases of GenAI is probably in the other two categories (non-binary and \u2018do not wish to disclose\u2019),\nnot primarily related to research integrity considerations. but these contain only few observations.\n5\nJ.P. Andersen et al. T e c h n o l o g y in S o c i e t y 81 (2025) 102813\nFig. 2. Distribution of aggregated use and research integrity assessment scores. Each panel shows the aggregated research integrity assessment (left column) or\naggregated use (right column) across research field, knowledge production ways, gender and academic age (top to bottom). Colours in knowledge production ways\ndistributions correspond to colours in research field.\nIn terms of academic age, we observe a clear pattern in usage of answer the question about if they had any specific tools in mind while\nGenAI tools, with more junior scholars using GenAI for more different answering the survey (Fig. 2 \u2013 figuresupplement 1). Copilot (both\npurposes than their senior colleagues. In terms of research integrity Microsoft and GitHub) was the second most mentioned tool (n =176).\nassessment, no substantial differences between respondents from Other tools mentioned include Grammarly (n =101), Google\u2019s Bard (n\ndifferent academic ages were observed. This means junior scholars have =76), Dall-E (n =74) and DeepL (n =69).\nbeen quicker to adopt GenAI tools for various use cases than their senior\ncolleagues, even with similar assessment of the appropriateness of such 3.2. Factor analysis\nusage.\nIf we look at the GenAI tools that respondents had in mind when We used exploratory factor analysis to identify patterns in the vari-\nanswering the survey, most respondents indicated to be thinking of ance of research integrity assessments. We identified three clusters,\nChatGPT (n =1550), while 894 respondents answered \u2018no\u2019 or did not supported by the eigenvalues in the parallel analysis (Supplementary\n6\nJ.P. Andersen et al. T e c h n o l o g y in S o c i e t y 81 (2025) 102813\nFig. 7). We also checked the correspondence between observed and more problematic to use GenAI for data analysis (da1-5) than re-\nmultiply imputed responses (Supplementary Fig. 8) and consider the searchers in the other two clusters. In the open text field comments from\ncorrespondence sufficient to incorporate imputed responses for a more cluster 2, researchers provide some clarification of this pattern. Re-\ncomplete data material. Factor loadings underlying the cluster analysis spondents referred to GenAI as \u201ca glorified spell checker\u201d (23440), and\nare available in Supplementary Fig. 9. mentioned that it is potentially useful \u201c[n]ot so much in actual research,\nThe factor analysis revealed three clusters of research integrity but for various kinds of help-services, especially in connections with language\nassessment of GenAI use cases among respondents (Fig. 3), based on a k- polishing/translation and editing\u201d (20622). Overall, it seems that re-\nmeans clustering of individual factor scores. The clusters differentiate searchers in this cluster are generally sceptical towards using GenAI for\nfrom each other by highlighting different types of integrity assessments research purposes, potentially with the sole exceptions of using GenAI as\nof GenAI use in research. Cluster 1 could be labelled \u201cGenAI as a work an assistant in the more \u201clanguage related\u201d aspects of the research\nhorse\u201d, with 893 respondents (35.2 %). In this cluster we find re- process. The positive assessments are very few and weak in this cluster.\nsearchers who consider using GenAI to create and edit software codes for Finally, in cluster 3, which could be labelled \u201cGenAI as a research\nanalysis and simulation (da1-2), to support statistical analysis (da3) and accelerator\u201d, we find 1032 researchers (40.7 %) who are generally very\nto help recognize patterns in data (da4) as good research practices. On positive in their assessment of GenAI. They are positive about using\nthe other hand, researchers in this cluster are more sceptical towards GenAI in almost all use cases, particularly in relation to data analysis and\nusing GenAI in the peer review process (cf. pub6 and pub7) than re- research design. There are only a few use cases with a slightly more\nsearchers in the two other clusters. They also score using GenAI in the varied/negative assessment, e.g. the creation of synthetic datasets (dc3)\n\u2018Idea generation phase\u2019 (idea1-5) lower than researchers in the other and identifying ethical issues in research (dc5). Again, the comments do\ntwo clusters. If we look at the comments from researchers in this cluster, not directly explain why the researchers in this cluster score these use\nmade in the open text field in the survey [37], some researchers, point cases as they do. The comments deal with many different issues, but\nout that GenAI \u201cis good when used for tedious tasks like formatting, editing, some researchers mention that using GenAI tools help them become\ngenerating a code for idea that you have in mind, generating drafts, etc, and more productive:\nterrible for creative tasks\u201d (ID2561), that it is \u201cproblematic to be using\n\u201cI do believe that AI is excellent practice for increasing productivity\ngenerative AI in creating articles or other written materials\u201d (ID13760), but\nespecially in the form of content/outline SUGGESTION (not copy-pasting\nthat GenAI can be good for \u201cchecking language and reviewing code\u201d\nit for the final version of a paper as content might be faulty and is often too\n(ID12608). This cluster is thereby mainly characterised by using GenAI\ngeneral), language improvement (here AI is excellent and I don\u2019t see any\nas a tool to speed up, process, or help researchers with technical issues in\nethical/moral problems with it as long as input data is not confidential),\nrelation to their research \u2013 i.e. as a \u201cwork horse\u201d.\nand generating first drafts of sections based on my own (unstructured)\nIn cluster 2 \u2013 tentatively called \u201cGenAI as a language assistant\ncontent/thoughts (again, I do not see any problem with that as the content\nonly\u201d, we find the most sceptical respondents (n =609, 24.0 %). They\nstill comes from me).\u201d (ID20164).\ngenerally assess the use of GenAI more negatively than the other clus-\nters, but it is also in this cluster where we find the most \u201cneutral\u201d re- In terms of reported use, all three clusters follow a similar pattern\nsponses. Positive assessments are mainly found for use cases related to regarding the use cases for which higher/lower use of GenAI is self-\nlanguage editing, e.g. refine and edit language of research proposals reported. The clusters only differentiate in the extent to which they\n(rd3), transcribe recordings of research material (dc4) and propose ti- report higher/lower use, with respondents in cluster 3 consistently\ntles, keywords, or abstracts, edit research articles for readability and reporting highest use for every use case. Hence, while we observe\nformatting references (pub3-5). Particularly, cluster 2 researchers find it relatively strong differences in terms of research integrity assessment,\nFig. 3. Research integrity assessment responses and own use across all use cases, split by factor loading clusters.\n7\nJ.P. Andersen et al. T e c h n o l o g y in S o c i e t y 81 (2025) 102813\nthese only weakly reflect in respondents\u2019 self-reported use of GenAI proportion of humanities scholars (36.6 %) compared to the other four\nacross different clusters. main areas of research (from 20.6 to 23.4 %). If we look at differences\nIf we look at the demographic distribution of respondents over the between researchers using different knowledge production ways, we\nthree identified clusters (Fig. 4), we do not find any differences in how similarly see that a greater proportion of the humanities scholars, who\nmen and women assess the research integrity of different GenAI use work on data produced by themselves, are to be found in cluster 2 (41.5\ncases. Similarly, there are only minor differences in how different %), compared to the other nine knowledge production ways. However,\nseniority groups (PhD students, and starting, consolidated and advanced many theoretical natural scientists (32.1 %), humanities scholars\nresearchers) assess what is good use of GenAI. Only in relation to main working on existing data (30.4 %), and qualitative social scientists (29.9\nareas of research and knowledge production ways, we find more pro- %) can also be found in this cluster of GenAI sceptics. Whereas, in\nnounced differences. comparison, much fewer quantitative social scientists (13.8 %), exper-\nIn cluster 1 \u2013 \u201cGenAI as a work horse\u201d \u2013 we find researchers from all imental natural scientists (17.8 %), basic medical scientists (19 %) and\ntypes of epistemic backgrounds. However, researchers from the hu- experimental technical scientists (19.3 %) are represented in this cluster.\nmanities, who work on data produced by themselves (26.4 %), clinical In cluster 3 \u2013 \u201cGenAI as a research accelerator\u201d \u2013 we find a smaller\nmedical researchers (30.5 %), and theoretical natural scientists (31.7 %) proportion of researchers from the humanities (32.9 %) compared to the\nare less well represented in this cluster compared to researchers working other main areas of research. For example, in the technical sciences,\nwith other ways of producing knowledge, who have a representation of 44.1 % of researchers belong to this cluster, and in medicine it is 42.9 %.\nbetween 34.1 % and 40 % in cluster 1. If we look at the 10 different knowledge production ways, the human-\nIn cluster 2 \u2013 \u201cGenAI as a language assistant only\u201d \u2013 we find a bigger ities scholars are joined by the qualitative social scientists (33.3 %) and\nFig. 4. Demographic distribution of respondents over factor clusters. Each heatmap shows the distribution of research age, gender, knowledge production way\nand research field for the three clusters of observations identified in the factor analysis.\n8\nJ.P. Andersen et al. T e c h n o l o g y in S o c i e t y 81 (2025) 102813\nthe theoretical natural scientists (36.2 %) in being proportionally less regulations and community norms in shaping responsible GenAI use.\nrepresented in this cluster compared to other knowledge production While top-down regulations can provide a clear framework for good\nways. research practices, their effectiveness is contingent on their alignment\nwith the values and practices of the research community. The case of\n4. Discussion peer review exemplifies this dynamic. It is among the few use cases\nsurveyed in our study for which clear guidelines exist, prohibiting the\nIn this study, we set out to explore the use and assessment of GenAI in use of GenAI for this purpose [34]. Simultaneously, we observe that this\nvarious research practices across gender, seniority, main areas of use case is among those with the strongest moral objections, perhaps\nresearch, and knowledge production ways. The results show that there influenced by the guidelines themselves. However, it is equally plausible\nwere no or only very minor differences in the use and assessment in that the guidelines were formulated in response to perceived\nrelation to gender. Some variations were found related to seniority and pre-existing community concerns. This interplay highlights the need for\nbigger differences were found related to the different main areas of a balanced approach to regulating GenAI in research. While top-down\nresearch. As Fig. 2shows, both the patterns of use and assessment are frameworks may help shape standards, rigid, top-down frameworks\nfairly similar within and across main areas of research. that disregard community norms risk being ineffective or even coun-\nAn interesting finding of the study, which nuances these minor dif- terproductive [35]. Conversely, a purely bottom-up approach may lead\nferences, is that we find the largest disagreement of how to assess the to inconsistent practices and tensions between diverse research areas. In\nresearch integrity of particular use cases \u2013 how good a practice they are addition, our respondents indicate a clear desire for more support from\nperceived to be \u2013 in the group of the non- or infrequent users. This means their institutions (e.g. training and access to relevant infrastructure), to\nthat the agreement in assessment increases with use and indicates that allow for well-considered and responsible use of GenAI for research\nfamiliarity with GenAI leads to similar, usually more positive, evalua- purposes.\ntions. This points to a need for more training for researchers within all The latter touches on the wider ethical considerations of using GenAI\nfields; a need which is also echoed in a number of the qualitative com- for research purposes. As outlined by others, GenAI poses various ethical\nments to the survey. challenges to researchers [27]. Our survey adopted relatively inclusive\nThis difference in use \u2013 that some use GenAI more than others \u2013 is terms to refer to such ethical considerations when asking for re-\nfurther highlighted in the factor analysis presented above, where three spondents\u2019 assessments. We used the language of \u2018responsible research\nmain clusters of GenAI users in Danish academia are identified: \u201cGenAI practices\u2019 in relation to specific research tasks, thereby likely triggering\nas a work horse\u201d, \u201cGenAI as language assistant only\u201d, and \u201cGenAI as a assessments of ethical aspects most closely related to integrity and pri-\nresearch accelerator\u201d. Interestingly, the use patterns across the clusters vacy [23]. In their responses to the open questions, some of our re-\nare remarkably similar, but the degree of use differs. This means that the spondents nevertheless referred to wider ethical principles including\nresearchers in the three clusters use (and do not use) GenAI for the same those of equity, fairness and accountability. The broader impact of using\nthings, but to a varied degree. We also observe a moderately positive GenAI, including issues such as social and climate justice and referred to\ncorrelation between research integrity assessment of use cases and re- as the final principle in Knoechel et al. [27] framework for responsible\nported use of the same cases. Our data do not allow identification of the GenAI usage, were hardly explicitly touched upon by our respondents\ndirection of causality (i.e. whether more use creates a more positive though. In contrast, issues such as accuracy, trustworthiness and privacy\nview of GenAI or the other way around). Nevertheless, this correlation is were omnipresent in our respondents\u2019 comments. This aligns well with\nfairly weak, and many respondents report positive assessments of use calls for regulation noted by ethicists Resnik and Hosseini [36].\ncases but no actual use of them. This suggests that non-use is often re-\nported not because of research integrity concerns but due to other rea- 4.1. Limitations\nsons, such as lack of awareness that GenAI can be used for this purpose,\ninsufficient skills on how to use GenAI or a lack of confidence that peers While our study provides valuable insights into the use and assess-\nwill approve of GenAI usage and concerns about potential negative ment of research integrity of GenAI in the research process across\nconsequences. various research fields in the Danish university context, it is important to\nHowever, the factor analysis also reveals some interesting differ- acknowledge a number of limitations that may influence the interpre-\nences between disciplines and different ways of producing knowledge tation of the findings and their generalizability.\nacross the three clusters. These differences are most pronounced in First, there might be different interpretations among survey partici-\n\u201cGenAI as a research accelerator\u201d (Cluster 3) and in Cluster 2, \u201cGenAI as pants of what constitutes a GenAI tool. While many researchers thought\na language assistant only\u201d. In Cluster 3, the most GenAI-positive group, about tools like ChatGPT when filling in the survey, others had more\nwe find mostly researchers from the technical and medical sciences, as general tools in mind like Grammarly. Other researchers note that they\nwell as quantitative social scientists and experimental natural scientists. had highly specialized tools in mind, developed for particular research\nIn Cluster 2, on the other hand, we have more researchers from the tasks. This variation can influence the reported use and research integ-\nhumanities, qualitative social science, and theoretical natural science rity assessments of the tools. Similar considerations might have affected\ncompared to other knowledge production ways. This pattern might the interpretation of use cases, which might have different connotations\nreflect important differences in the way in which knowledge is pro- within different knowledge production ways and epistemic cultures (e.g.\nduced; in the methods used and the overall approach to doing research, the creation of \u2018synthetic data\u2019).\nincluding the normative frameworks associated with these diverse ap- Second, the study is based on responses from a specific subset of\nproaches to knowledge production. Danish university researchers. The sample may not be fully represen-\nThis difference can be described as a difference between nomothetic tative of the entire Danish academic community, considering potential\nand ideographic research areas ([33] [1894]) \u2013 or perhaps more pre- biases in who chose to participate in the survey. The low number of\ncisely, between more positivist ways of doing research, on the one side, respondents in certain categories, e.g., non-binary and \u201cdo not wish to\nand interpretative approaches on the other side. It seems clear that the disclose gender\u201d options, also constraints the ability to draw any con-\nmore interpretivist researchers are more sceptical towards GenAI, and clusions for these specific groups. Moreover, respondents might under-\nthat they also use the \u201cneutral\u201d option more than the other clusters. This report or overreport the use of GenAI tools and their research integrity\nmay be because use cases are seen as irrelevant to their research assessments due to personal beliefs or perceived expectations. Research\napproach, e.g. generating hypotheses or suggesting experimental integrity assessments are subjective and vary based on individual values,\nparameters. backgrounds, and disciplinary/field norms [22]. This diversity may lead\nOur study also demonstrates the complex interplay between to a wide range of integrity assessments for similar use cases. The\n9\nJ.P. Andersen et al. T e c h n o l o g y in S o c i e t y 81 (2025) 102813\ndistribution of research integrity assessments indicates that there are administration, Methodology, Investigation, Formal analysis, Data\nmany different opinions on GenAI use, which might be influenced by curation, Conceptualization. Serge P.J.M. Horbach: Writing \u2013 review &\nindividual skills and experiences, field and disciplinary standards, and editing, Writing \u2013 original draft, Validation, Project administration,\npersonal ethics. Social desirability might, for example, have played a Methodology, Investigation, Formal analysis, Data curation, Conceptu-\nrole in how researchers have answered. alization. Evanthia Kalpazidou Schmidt: Writing \u2013 review & editing,\nThird, the field of GenAI is evolving fast, and tools and their appli- Writing \u2013 original draft, Validation, Methodology, Investigation, Formal\ncations can change drastically over short periods. New tools emerge and analysis, Data curation, Conceptualization. Jesper W. Schneider:\nexisting ones are updated, potentially changing use patterns and Writing \u2013 review & editing, Writing \u2013 original draft, Visualization,\nresearch integrity perceptions. Therefore, our findings should be Validation, Project administration, Methodology, Investigation, Formal\nconsidered a snapshot of the state of affairs at a specific time and analysis, Data curation, Conceptualization. Mads P. S\u00f8rensen: Writing\ncontext, not necessarily generalizable to other settings. \u2013 review & editing, Writing \u2013 original draft, Visualization, Validation,\nFourth, our study does not extensively explore the influence of cul- Project administration, Methodology, Investigation, Formal analysis,\ntural and institutional factors on the use of GenAI tools and research Data curation, Conceptualization.\nintegrity assessment of use cases. Universities may have different pol-\nicies and support structures that impact on how researchers engage with Ethics declaration\nthe tools.\nFinally, while we studied a broad array of GenAI use cases, there are The study obtained ethical approval from the Ethical Review Board\nobviously other potential applications of GenAI in research that were not of Aarhus BSS, Aarhus University, under document number: BSS-2023-\ncovered in our research. Future studies could expand the range of GenAI 132.\ntools and use cases to provide a more comprehensive picture.\n5. Conclusion and implications Declaration of competing interest\nBased on an initial collection of empirical evidence on the use of The authors declare no competing interests.\nGenAI and research integrity assessments among researchers, this study\nhas addressed pressing issues regarding GenAI\u2019s application, percep-\nAcknowledgements\ntions, and ethical dilemmas in research. This provides a necessary base\nfor, and points towards important future research still to come. Among\nThe authors would like to thank the 2534 respondents who\nthese are e.g. augmented empirical data to identify causal factors behind\ncompleted the survey and the 533 respondents, who completed parts of\ndiverse perceptions of GenAI use and patterns of adoption, barriers and\nit. We would also like to thank student assistant, Simon Nielsen, from the\nscepticism across researchers of diverse backgrounds. Such follow up is\nDanish Centre for Studies in Research and Research Policy, Aarhus\nrequired to provide more in-depth evidence-based interpretability and\nUniversity, for his help with parts of the qualitative analysis, and PhD\nrecommendations for policy and support frameworks in academia.\nstudent Emil Dolmer Alnor for help extracting the participant informa-\nOwing to the fast development of GenAI and its many different ap-\ntion from university web pages.\nplications for research purposes, it is currently challenging to propose\nclear recommendations or guidelines for its usage. Any regulations\nAppendix A. Supplementary data\nproposed are likely to become obsolete quickly due to the speed of\ntechnological advancements. Therefore, we suggest following Knoechel\nSupplementary data to this article can be found online at https://doi.\net al. [27] approach in drafting principles that are flexible enough for\norg/10.1016/j.techsoc.2025.102813.\nimplementation across various research fields. This approach is also\nsupported by our data, which indicates that regulations and guidelines\nData availability\nhave to take disciplinary differences (i.e. differences in knowledge\nproduction ways) into account to be effective. To ensure successful\nAnonymised data is available at https://doi.org/10.17605/OSF.\nintegration, we suggest developing tailored strategies for diverse\nIO/6HTFS.\nresearch contexts, working closely together with experts in those spe-\ncific fields. Such a collaborative approach would ensure that strategies\nare tailored to the specific needs of the single research environments, References\nthereby minimizing the risks of misalignment with the practices and\n[1] H. Benbya, F. Strich, T. Tamm, Navigating generative artificial intelligence\nexperiences of individual researchers. Local workshops, focus groups,\npromises and perils for knowledge and creative work, J. Assoc. Inf. Syst. Online 25\nand other collaborative activities could facilitate such a process, and it is (1) (2024) 23\u201336, https://doi.org/10.17705/1jais.00861.\nrecommended to involve the research community at large, including [2] A.M. Al-Zahrani, The impact of generative AI tools on researchers and research:\nimplications for academia in higher education, Innovat. Educ. Teach. Int. (2023)\nresearchers as well as learned societies, funders, publishers, and uni- 1\u201315, https://doi.org/10.1080/14703297.2023.2271445.\nversity administrations. [3] R. Peres, M. Schreier, D. Schweidel, A. Sorescu, On ChatGPT and beyond: how\ngenerative artificial intelligence may affect research, teaching, and practice, Int. J.\nRes. Market. 40 (2) (2023) 269\u2013275, https://doi.org/10.1016/j.\nCRediT authorship contribution statement\nijresmar.2023.03.001.\n[4] A. Korinek, Generative AI for economic research: use cases and implications for\nJens Peter Andersen: Writing \u2013 review & editing, Writing \u2013 original economists, J. Econ. Lit. 61 (4) (2023) 1281\u20131317, https://doi.org/10.1257/\njel.20231736.\ndraft, Visualization, Validation, Software, Project administration,\n[5] W.J. Xie, A. Warshel, Harnessing generative AI to decode enzyme catalysis and\nMethodology, Investigation, Formal analysis, Data curation, Conceptu- evolution for enhanced engineering, Natl. Sci. Rev. 10 (12) (2023), https://doi.\nalization. Lise Degn: Writing \u2013 review & editing, Writing \u2013 original org/10.1093/nsr/nwad331.\ndraft, Validation, Project administration, Methodology, Investigation, [6] C.A. Gao, F.M. Howard, N.S. Markov, E.C. Dyer, S. Ramesh, Y. Luo, A.T. Pearson,\nComparing scientific abstracts generated by ChatGPT to real abstracts with\nFormal analysis, Data curation, Conceptualization. Rachel Fishberg: detectors and blinded human reviewers, npj Digital Medicine 6 (1) (2023), https://\nWriting \u2013 review & editing, Writing \u2013 original draft, Visualization, doi.org/10.1038/s41746-023-00819-6.\nValidation, Project administration, Methodology, Investigation, Formal [7] F. Larosa, S. Hoyas, J. Garc\u00eda-Mart\u00ednez, J.A. Conejero, F. Fuso Nerini, R. Vinuesa,\nHalting generative AI advancements may slow down progress in climate research,\nanalysis, Data curation, Conceptualization. Ebbe K. Graversen: Writing Nat. Clim. Change 13 (6) (2023) 497\u2013499, https://doi.org/10.1038/s41558-023-\n\u2013 review & editing, Writing \u2013 original draft, Validation, Project 01686-5.\n10\nJ.P. Andersen et al. T e c h n o l o g y in S o c i e t y 81 (2025) 102813\n[8] A. Birhane, A. Kasirzadeh, D. Leslie, S. Wachter, Science in the age of large [24] M. Hosseini, S.P.J.M. Horbach, K. Holmes, T. Ross-Hellauer, Open science at the\nlanguage models, Nature Reviews Physics 5 (5) (2023) 277\u2013280, https://doi.org/ generative AI turn: an exploratory analysis of challenges and opportunities, Open\n10.1038/s42254-023-00581-4. Science Framework (2024), https://doi.org/10.31235/osf.io/zns7g.\n[9] H. Else, Abstracts written by ChatGPT fool scientists, Nature 613 (7944) (2023), [25] EU IPO, Navigating the complexities of generative AI in intellectual property:\nhttps://doi.org/10.1038/d41586-023-00056-7, 423-423. challenges and opportunities. https://www.euipo.europa.eu/en/news/navigatin\n[10] L. Messeri, M.J. Crockett, Artificial intelligence and illusions of understanding in g-the-complexities-of-generative-ai-in-intellectual-property-challenges-and-oppo\nscientific research, Nature 627 (8002) (2024) 49\u201358, https://doi.org/10.1038/ rtunities, 2023.\ns41586-024-07146-0. [26] P. Hacker, A. Engel, M. Mauer, Regulating ChatGPT and Other Large Generative AI\n[11] R. Van Noorden, J.M. Perkel, AI and science: what 1,600 researchers think, Nature Models 2023 ACM Conference on Fairness, Accountability, and Transparency,\n621 (7980) (2023) 672\u2013675, https://doi.org/10.1038/d41586-023-02980-0. 2023.\n[12] Committee on Publication Ethics, Authorship and AI tools. https://publicationeth [27] T.-D. Knoechel, K. Schweizer, O.A. Acar, A.M. Akil, A.H. Al-Hoorie, F. Buehler,\nics.org/cope-position-statements/ai-author, 2024. M. Elsherif, A. Giannini, E. Heyselaar, M. Hosseini, V. Ilangovan, M. Kovacs, Z. Lin,\n[13] W.M. Hepkema, S.P.J.M. Horbach, J.M. Hoek, W. Halffman, Misidentified M. Liu, A. Peeters, D. van Ravenzwaaij, M.A. Vranka, Y. Yamada, Y.-F. Yang,\nbiomedical resources: journal guidelines are not a quick fix, Int. J. Cancer 150 (8) B. Aczel, Principles for responsible AI usage in research, Open Science Framework\n(2021) 1233\u20131243, https://doi.org/10.1002/ijc.33882. (2024), https://doi.org/10.31234/osf.io/g3m5f.\n[14] T. Petricini, C. Wu, S.T. Zipf, Perceptions about generative AI and ChatGPT use by [28] T. Ravn, M.P. S\u00f8rensen, Exploring the gray area: similarities and differences in\nfaculty and college students, Open Science Framework (2023), https://doi.org/ questionable research practices (QRPs) across main areas of research, Sci. Eng.\n10.35542/osf.io/jyma4. Ethics 27 (4) (2021), https://doi.org/10.1007/s11948-021-00310-z.\n[15] C. Shaw, L. Yuan, D. Brennan, S. Martin, N. Janson, K. Fox, G. Bryant, GenAI in [29] M. Hutson, Rules to keep AI in check: nations carve different paths for tech\nHigher Education \u2013 Fall 2023 Update, Turnitin, 2023. https://tytonpartners.co regulation, Nature 620 (7973) (2023) 260\u2013263, https://doi.org/10.1038/d41586-\nm/app/uploads/2023/10/GenAI-IN-HIGHER-EDUCATION-FALL-2023-UPDATE- 023-02491-y.\nTIME-FOR-CLASS-STUDY.pdf. [30] S.v. Buuren, K. Groothuis-Oudshoorn, Mice: multivariate imputation by chained\n[16] S.A. Bin-Nashwan, M. Sadallah, M. Bouteraa, Use of ChatGPT in academia: equations inR, J. Stat. Software 45 (3) (2011), https://doi.org/10.18637/jss.v045.\nacademic integrity hangs in the balance, Technol. Soc. 75 (2023), https://doi.org/ i03.\n10.1016/j.techsoc.2023.102370. [31] W. Revelle, Psych: Procedures for Psychological, Psychometric, and Personality\n[17] L. Nordling, How ChatGPT is transforming the postdoc experience, Nature 622 Research, CRAN, 2024. Version 2.4.6.26, https://cran.r-project.org/web/packag\n(7983) (2023) 655\u2013657, https://doi.org/10.1038/d41586-023-03235-8. es/psych/index.html.\n[18] B. Owens, How Nature readers are using ChatGPT, Nature 615 (7950) (2023), [32] J.W. Schneider, N. Allum, J.P. Andersen, M.B. Petersen, E.B. Madsen, N. Mejlgaard,\nhttps://doi.org/10.1038/d41586-023-00500-8, 20-20. R. Zachariae, Is something rotten in the state of Denmark? Cross-national evidence\n[19] R. Watermeyer, L. Phipps, D. Lanclos, C. Knight, Generative AI and the automating for widespread involvement but not systematic use of questionable research\nof academia, Postdigital Science and Education 6 (2) (2023) 446\u2013466, https://doi. practices across all fields of research, PLoS One 19 (8) (2024), https://doi.org/\norg/10.1007/s42438-023-00440-6. 10.1371/journal.pone.0304342.\n[20] European Commission, & European Research Council Executive Agency, Use and [33] W. Windelband, History and natural science, Theor. Psychol. 8 (1) (2016) 5\u201322,\nImpact of Artificial Intelligence in the Scientific Process \u2013 Foresight, P. O. o. t. E. https://doi.org/10.1177/0959354398081001 [1894]).\nUnion, 2023. [34] L.A. Nogueira, J.O. Rein, Chatbots: to cite or not to cite? (Part 1). The Scholarly\n[21] J.K. Kim, M. Chua, M. Rickard, A. Lorenzo, ChatGPT and large language model Kitchen, 2024. https://scholarlykitchen.sspnet.org/2024/06/19/chatbots-to-cite-\n(LLM) chatbots: the current state of acceptability and a proposal for guidelines on or-not-to-cite-part-1/.\nutilization in academic medicine, J. Pediatr. Urol. 19 (5) (2023) 598\u2013604, https:// [35] S.P.J.M. Horbach, M.P. S\u00f8rensen, N. Allum, A.-K. Reid, Disentangling the local\ndoi.org/10.1016/j.jpurol.2023.05.018. context\u2014imagined communities and researchers\u2019 sense of belonging, Sci. Publ.\n[22] A. Gray, ChatGPT \"contamination\": estimating the prevalence of LLMs in the Pol. 50 (4) (2023) 695\u2013706, https://doi.org/10.1093/scipol/scad017.\nscholarly literature, arXiv (2024), https://doi.org/10.48550/arXiv.2403.16887. [36] D.B. Resnik, M. Hosseini, The ethics of using artificial intelligence in scientific\n[23] Y. Ning, S. Teixayavong, Y. Shang, J. Savulescu, V. Nagaraj, D. Miao, M. Mertens, research: new guidance needed for a new tool, AI and Ethics (2024), https://doi.\nD.S.W. Ting, J.C.L. Ong, M. Liu, J. Cao, M. Dunn, R. Vaughan, M.E.H. Ong, J.J.- org/10.1007/s43681-024-00493-8.\nY. Sung, E.J. Topol, N. Liu, Generative artificial intelligence and ethical [37] J.W. Schneider, M.P. S\u00f8rensen, S.P.J.M. Horbach, J.P. Andersen, R. Fishberg, E.\nconsiderations in health care: a scoping review and ethics checklist, The Lancet K. Graversen, L. Degn, E.K. Schmidt, Research integrity AI survey, Open Science\nDigital Health 6 (11) (2024) e848\u2013e856, https://doi.org/10.1016/s2589-7500(24) Framework (2024), https://doi.org/10.17605/OSF.IO/6HTF.\n00143-2.\n11"
  },
  "metadata": {
    "citation-376238636.ris": {
      "added_date": "2025-10-22T12:53:21.367185",
      "content_length": 207,
      "word_count": 30
    },
    "aalyze.jpeg": {
      "added_date": "2025-10-23T16:19:36.699393",
      "content_length": 978,
      "word_count": 163
    },
    "analysis.pdf": {
      "added_date": "2025-10-23T16:21:41.979576",
      "content_length": 10633,
      "word_count": 1466
    },
    "genai.pdf": {
      "added_date": "2025-10-23T16:18:06.577879",
      "content_length": 66757,
      "word_count": 10000
    }
  },
  "last_updated": "2025-10-23T16:21:41.979576"
}